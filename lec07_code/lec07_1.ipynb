{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinary Least Squares by Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# %matplotlib nbagg\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.random as rd\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic data (Linear function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100   # The number of samples\n",
    "b = np.array([10, 5])  # True parameter\n",
    "\n",
    "# Features\n",
    "x_train = (rd.rand(N) - 1/2)*5\n",
    "x_train = x_train.reshape((N,1))\n",
    "\n",
    "# Noise\n",
    "epsilon = rd.randn(N)*3   # Noise\n",
    "\n",
    "# Objective values\n",
    "y_train = b[0] + x_train[:,0] * b[1] + epsilon \n",
    "\n",
    "# Display the generated data\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "plt.scatter(x_train, y_train, s=10, alpha=0.9)\n",
    "plt.xlim([-3,3])\n",
    "plt.xlabel('input x',fontsize=10)\n",
    "plt.ylabel('output y',fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting by Ordinary Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and training\n",
    "reg = LinearRegression()\n",
    "reg.fit(x_train, y_train)\n",
    "\n",
    "# Display optimized coefficients\n",
    "print('Intercept: ' + str(reg.intercept_))\n",
    "print('Coefficient: ' + str(reg.coef_[0])) \n",
    "\n",
    "\n",
    "# Prediction\n",
    "x_test  = np.linspace(-3,3,10)\n",
    "x_test = x_test.reshape((10,1))\n",
    "y_pred = reg.predict(x_test)\n",
    "# print(y_pred)\n",
    "\n",
    "# Display results\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "plt.scatter(x_train, y_train, s=10, alpha=0.9)\n",
    "plt.scatter(x_test, y_pred, color='red', s=30)\n",
    "plt.plot(x_test, y_pred, 'r')\n",
    "plt.xlim([-3,3])\n",
    "plt.xlabel('input x',fontsize=10)\n",
    "plt.ylabel('output y',fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic data (Sine function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20  # The number of samples\n",
    "x_train = (rd.rand(N) - 1/2)*5  # Features\n",
    "epsilon = rd.randn(N)*0.1          # Noise\n",
    "y_train= np.sin(x_train) + epsilon  #Objective variable\n",
    "\n",
    "# Display the generated data\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "plt.scatter(x_train, y_train, s=10, alpha=0.9)\n",
    "plt.xlim([-3,3])\n",
    "plt.xlabel('input x',fontsize=10)\n",
    "plt.ylabel('output y',fontsize=10)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting by p-th order polynomial function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 10 # The degree of polynomial function\n",
    "\n",
    "# Generate feature vectors\n",
    "X_train = np.ones((x_train.size,0))\n",
    "for m in range(p+1):\n",
    "    X_train = np.c_[X_train, x_train**m]\n",
    "\n",
    "# Training\n",
    "reg.fit(X_train,y_train)\n",
    "\n",
    "# Display optimized coefficient\n",
    "print('Intercept: ' + str(reg.intercept_))\n",
    "print('Coefficient: ' + str(reg.coef_)) \n",
    "\n",
    "# Prediction for test data\n",
    "x_test  = np.linspace(-3,3,20)\n",
    "x_test = x_test.reshape((20,1))\n",
    "X_test = np.ones((x_test.size,0))\n",
    "for m in range(p+1):\n",
    "    X_test = np.c_[X_test, x_test**m]\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "# Display the result\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "plt.scatter(x_train, y_train, s=10, alpha=0.9)\n",
    "# plt.scatter(x_test, y_pred, color='red', s=30)\n",
    "plt.plot(x_test, y_pred, 'r')\n",
    "plt.xlim([-3,3])\n",
    "plt.xlabel('input x',fontsize=10)\n",
    "plt.ylabel('output y',fontsize=10)\n",
    "plt.ylim([-2,2])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the optimal degree by 5-fold cross-validation (CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_degree = 20\n",
    "mse = list()\n",
    "for p in range(max_degree+1): # The degree of polynomial function\n",
    "\n",
    "    # Generate feature vectors\n",
    "    X_train = np.ones((x_train.size,0))\n",
    "    for m in range(p+1):\n",
    "        X_train = np.c_[X_train, x_train**m]\n",
    "        \n",
    "    # predict output of validation samples during CV\n",
    "    y_pred = cross_val_predict(reg, X_train, y_train, cv=5)\n",
    "    \n",
    "    #compute MSE (mean squared error)\n",
    "    mse.append( np.mean((y_pred-y_train)**2))\n",
    "\n",
    "p_opt = np.argmin(mse)\n",
    "    \n",
    "# plot validation error\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.semilogy(range(max_degree+1), mse,'.-')\n",
    "plt.semilogy(p_opt, mse[p_opt],'ro-')\n",
    "plt.xlim([0,max_degree])\n",
    "plt.xticks(range(max_degree+1))\n",
    "plt.xlabel('Degree')\n",
    "plt.ylabel('MSE')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict outputs by the plynomial regression model with the optimized degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate feature vectors\n",
    "X_train = np.ones((x_train.size,0))\n",
    "for m in range(p_opt+1):\n",
    "    X_train = np.c_[X_train, x_train**m]\n",
    "\n",
    "# Training\n",
    "reg.fit(X_train,y_train)\n",
    "\n",
    "# Display optimized coefficient\n",
    "print('Intercept: ' + str(reg.intercept_))\n",
    "print('Coefficient: ' + str(reg.coef_)) \n",
    "\n",
    "# Prediction for test data\n",
    "x_test  = np.linspace(-3,3,20)\n",
    "x_test = x_test.reshape((20,1))\n",
    "X_test = np.zeros((x_test.size,0))\n",
    "for m in range(p_opt+1):\n",
    "    X_test = np.c_[X_test, x_test**m]\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "# Display the result\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "plt.scatter(x_train, y_train, s=10, alpha=0.9)\n",
    "# plt.scatter(x_test, y_pred, color='red', s=30)\n",
    "plt.plot(x_test, y_pred, 'r')\n",
    "plt.xlim([-3,3])\n",
    "plt.xlabel('input x',fontsize=10)\n",
    "plt.ylabel('output y',fontsize=10)\n",
    "plt.ylim([-2,2])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
